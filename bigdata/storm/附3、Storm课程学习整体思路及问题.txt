问题：
1、集群如何启动，任务如何执行？
	java -server nimubs，supervisor
	client--->createTopology(序列化)--->提交jar到nimbuinbox--->nimbus分配任务(task总数/worker数)---写到zk。
										启动worker<------识别自己的任务<----supervisor---->watch----zk
										                启动Spout/Bolt----TaskInfo<------worker---->zk
	集群架构中的各个模块如何启动？
	nimbus：用户启动
	supervisor：用户启动
	worker：supervisor启动
	Task：worker启动
	
	任务如何分配，如何执行？
		看图说话
		
2、集群如何通信？
	集群架构中的各个模块是如何通信的？外部通信
	拓扑程序中的各个Task是如何通信的？内部通信
	
3、如何保证消息的不丢失
	ack-fail机制如何实现的？
	成功：ack方法
	失败：fail方法
	
4、[动手练习]尝试自己实现一个类似storm数据执行的框架

	1,任务分配
		----->Task总数
		----->可用worker数量
	2,通信机制
		----->去zk获取每个组件的任务
		----->启动不同服务
			  nimbus，手动 java -server xxx.jar main-class
			  superv，手动 java -server xxx.jar main-class
			  worker，supervisor启动------java -server xxx.jar main-class(main(Worker.mk_work(new Worker())))
			  Task, Worker启动Task--------Jvm--->Task.mk_Task()
	3,心跳机制
		10:18 client:thread1---zk ---tag=true{object{javaBean}}
		10:19 server:thread2------>thread1tag=true------thread1tag=false
		10:19 30s client:thread1------>thread1tag=true------thread1tag=false------thread1tag=true
		10:20 server:thread2------>thread1tag=true------thread1tag=false------thread1tag=true------thread1tag=false

	4、任务执行(数据流)
		spout.nextTuple(tuple)----streamGrouping---> incomingQueue-------->bolt1.exeute(tuple)-----streamGrouping----> incomingQueue-------->bolt2.exeute(tuple)
		
	[实现数据执行的框架]	
		spout-----线程1
		incomingQueue------queue
		bolt1-----线程2
		incomingQueue------queue
		bolt2-----线程3
		
		需要技术：
			线程池----->Exeutes.newFixPool(3)
			队列------->ArrayBolckingQueue(1000)
		
		伪代码：
			
			MyStrom{
				main(){
				//1、配置一个线程池
				//2、向线程池中提交任务
					spoutOutPutQueue = new ArrayBolckingQueue(1000)
					submit(new MySpout(spoutOutPutQueue))------collector.emit(tuple)------spoutOutPutQueue
					bolt1OutPutQueue = new ArrayBolckingQueue(1000)
					submit(new MyBolt1(spoutOutPutQueue,bolt1OutPutQueue))------>spoutOutPutQueue---->bolt1.execute(),collector.emit(tuple)------bolt1OutPutQueue
					submit(new MyBolt1(bolt1OutPutQueue))------>spoutOutPutQueue---->bolt1.execute()	
				}
			}
	5、Storm ack-fail机制源码核心类
		com.alibaba.jstorm.task.execute.spout.SpoutBatchCollector
			sendSpoutMsg 将新的tuple保存到缓存中
			sendBatch 发送数据-----发送两类数据---（dataTuple,ackTuple） dataTuple中包含一个messageID对象
			-ack-init
		com.alibaba.jstorm.task.execute.BoltBatchCollector
			sendBatch 批量发送，从messageID对象解析并ackTuple
			-ack_ack
		com.alibaba.jstorm.task.acker.Acker
			-ack-init
			-ack_ack
	
	
	
	
	
	
	
	
	
	
	